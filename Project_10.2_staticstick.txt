Q1. What are the three measures of central tendency?
The mean, median, and mode are three different measures of central tendency used to describe the central value of a dataset. They provide information about where the data tends to cluster or concentrate.
The three measures of central tendency are:
1. Mean: The mean is the arithmetic average of a set of data points. It is calculated by summing all the values and then dividing by the total number of data points. The mean represents the central value around which the data points tend to cluster.
2. Median: The median is the middle value of a dataset when the data points are arranged in ascending or descending order. If there is an even number of data points, the median is the average of the two middle values.
3. Mode: The mode is the value that appears most frequently in a dataset. It can be a single value (unimodal) or multiple values (bimodal, trimodal, etc.) if there are multiple equally occurring modes.
Q2. What is the difference between the mean, median, and mode? How are they used to measure the central tendency of a dataset?
The mean, median, and mode are three different measures of central tendency used to describe the central value of a dataset. They provide information about where the data tends to cluster or concentrate. The differences between the three measures and how they are used:
Mean:
* Definition: The mean is the arithmetic average of a set of data points. It is calculated by summing all the values and then dividing by the total number of data points.
* Use: The mean is used to measure the central tendency when we want to find the "average" or "typical" value of the dataset.
* Sensitivity to Outliers: The mean is sensitive to outliers, meaning extreme values can significantly impact its value.
Median:
* Definition: The median is the middle value of a dataset when the data points are arranged in ascending or descending order. If there is an even number of data points, the median is the average of the two middle values.
* Use: The median is used when the dataset is skewed or contains outliers. It provides a measure of central tendency that is not influenced by extreme values.
* Sensitivity to Outliers: The median is not sensitive to outliers, making it a robust measure of central tendency.
Mode:
* Definition: The mode is the value that appears most frequently in a dataset. It can be a single value (unimodal) or multiple values (bimodal, trimodal, etc.) if there are multiple equally occurring modes.
* Use: The mode is used to identify the most common occurrence or category in the dataset.
* Sensitivity to Outliers: The mode is not affected by outliers, as it only considers the frequency of values.

The mean, median, and mode are used to measure the central tendency of a dataset in different ways. The mean is useful when the dataset is approximately symmetric and not heavily influenced by outliers. The median is preferred when the dataset is skewed or contains extreme values, as it is robust to such situations. The mode is employed to identify the most common value or category in the dataset, regardless of the data's distribution.
Q3. Measure the three measures of central tendency for the given height data:
[178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]
In [1]:
import numpy as np


data = [178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]


In [2]:
#Mean of the data
np.mean(data)


Out[2]:
177.01875
In [3]:
#Median of the data
np.median(data)


Out[3]:
177.0
In [4]:
#import stats library for mode calculation
from scipy import stats
#Mode of the data
stats.mode(data)


/tmp/ipykernel_3225/1141732357.py:4: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  stats.mode(data)


Out[4]:
ModeResult(mode=array([177.]), count=array([3]))
Q4. Find the standard deviation for the given data:
[178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]
In [5]:
import numpy as np
data = [178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]
np.std(data)


Out[5]:
1.7885814036548633
Q5. How are measures of dispersion such as range, variance, and standard deviation used to describe the spread of a dataset? Provide an example.
Measures of dispersion, such as range, variance, and standard deviation, are used to describe the spread or variability of a dataset. They provide information about how much the data points deviate from the central tendency measures (mean, median, or mode) and how spread out the values are within the dataset.
1. Range:
* Definition: The range is the simplest measure of dispersion and represents the difference between the maximum and minimum values in a dataset.
* Use: The range gives an idea of the spread of the data from the lowest to the highest value.
* Example: Consider the following dataset of test scores: [70, 75, 80, 85, 90]. The range is calculated as 90 (maximum value) - 70 (minimum value) = 20. This means the spread of the test scores in the dataset is 20 points.
2. Variance:
* Definition: Variance is a measure of how far the data points are spread out from the mean. It quantifies the average squared deviation of each data point from the mean.
* Use: Variance provides an overall measure of dispersion, considering all data points.
* Calculation: The variance is computed by taking the sum of the squared differences between each data point and the mean, dividing it by the total number of data points (or n-1 for sample variance due to bessels correction to remove bias).
* Example: Continuing with the test scores dataset, let's assume the mean of the scores is 80. The variance would be calculated as [(70-80)^2 + (75-80)^2 + (80-80)^2 + (85-80)^2 + (90-80)^2] / 5 = 100. The variance of 100 indicates that the test scores have considerable variability from the mean score of 80.
3. Standard Deviation:
* Definition: The standard deviation is the square root of the variance. It is used to describe the typical amount of deviation or dispersion of data points from the mean.
* Use: Standard deviation provides a measure of the spread of data in the original units of measurement, making it easier to interpret and compare to the mean.
* Calculation: The standard deviation is computed by taking the square root of the variance.
* Example: In the test scores dataset, the standard deviation would be the square root of the variance, which is √100 = 10. This indicates that the typical deviation of the test scores from the mean of 80 is 10 points.
Q6. What is a Venn diagram?
A Venn diagram is a graphical representation used to illustrate the relationships and similarities between different sets or groups of data. It consists of overlapping circles or ellipses, each representing a separate set or category. The areas of overlap between the circles show the intersections or common elements shared by the sets.
Venn diagrams are particularly useful for visualizing set relationships and making comparisons between multiple datasets or categories. They are named after John Venn, a British mathematician and philosopher who introduced them in the 19th century.
Key features of a Venn diagram:
1. Circles (or Ellipses): Each circle in the diagram represents a different set or category. The circles may overlap to show the shared elements between the sets.
2. Overlapping Areas: The overlapping regions between the circles represent the intersections or common elements that belong to multiple sets simultaneously.
3. Non-overlapping Areas: The non-overlapping areas of each circle represent the elements unique to that particular set.
4. Labels: Venn diagrams often have labels or names associated with each set, making it clear which sets are being compared.
Q7. For the two given sets A = (2,3,4,5,6,7) & B = (0,2,6,8,10). Find:
(i) A ∩ B (ii) A ⋃ B
A = (2,3,4,5,6,7) B = (0,2,6,8,10)
1. A ∩ B : (A intersection B)
* This represents the A intersection B which means all the common elements between A and B.
* The output of the intersections of the above set will be (2,6)
2. A ⋃ B : (A union B)
* This represents the A union B which means all the elements of A and B ie,distinct elements.
* The output of the union of the above set will be (0,2,3,4,5,6,7,8,10)
In [6]:
A = {2,3,4,5,6,7}
B = {0,2,6,8,10}


a_intersection_b = A.intersection(B)
print("Intersection of A and B is : ",a_intersection_b)
a_union_b = A.union(B)
print("Union of A and B is : ",a_union_b)


Intersection of A and B is :  {2, 6}
Union of A and B is :  {0, 2, 3, 4, 5, 6, 7, 8, 10}


Q8. What do you understand about skewness in data?
Skewness is a statistical term that refers to the asymmetry or lack of symmetry in the distribution of a dataset. In a symmetrical distribution, the data is evenly distributed around the mean, with the left and right sides of the distribution mirroring each other. However, in a skewed distribution, the data is concentrated more towards one tail of the distribution, resulting in a longer tail on one side and a shorter tail on the other.
Skewness is an essential concept in data analysis as it helps to understand the shape and characteristics of a dataset. There are three types of skewness:
1. Positive Skewness (Right Skewness): In a positively skewed distribution, the majority of the data is concentrated towards the lower values (left side) of the distribution, and the tail extends to the right. This results in a longer right tail and a shorter left tail. The mean is typically greater than the median in positively skewed data.
* Here the Mean > Median >Mode
* Example of Positive Skewness:
Consider the distribution of household incomes in a country. Most households might have lower incomes, with a few extremely high-income households creating a long right tail.
   2. Negative Skewness (Left Skewness): In a negatively skewed distribution, the majority of the data is concentrated towards the higher values (right side) of the distribution, and the tail extends to the left. This results in a longer left tail and a shorter right tail. The mean is typically less than the median in negatively skewed data.
   * Here the Mean < Median < Mode
   * Example of Negative Skewness:
Consider the distribution of test scores in a difficult exam. Most students might score higher marks, but a few students might perform poorly, leading to a long left tail.
      3. Zero Skewness (Symmetrical/Gaussian Distribution): In a symmetrical distribution, the data is evenly distributed around the mean, and there is no skewness. The left and right sides of the distribution mirror each other, and the mean and median are approximately equal.
      * Here the Mean = Median = Mode
      * Example of Zero Skewness:
The distribution of heights in a population, where most people have average heights and the distribution is symmetrical around the mean height.
Q9. If a data is right skewed then what will be the position of median with respect to mean?


If a dataset is right-skewed, the median will be positioned to the left of the mean ie the value of median will be smaller than mean.
In a right-skewed distribution, the majority of the data is concentrated towards the lower values, resulting in a long tail extending to the right. This elongated tail on the right side is caused by a few extremely high values that pull the mean towards the right. As a result, the mean gets inflated by the presence of these high values, causing it to be larger than the median.
The median, on the other hand, is less influenced by extreme values or outliers because it represents the middle value of the dataset when the data is ordered. It is not affected by the specific values in the tail of the distribution.
Therefore, in a right-skewed distribution, where the tail is longer on the right, the median will be closer to the bulk of the data on the left side, and it will be to the left of the mean.
Q10. Explain the difference between covariance and correlation. How are these measures used in statistical analysis?
Covariance and Correlation are useful measures in statistical analysis to assess the relationship between two variables. Covariance gives the direction of the relationship, while correlation provides a standardized measure of both direction and strength.
Covariance:
Covariance measures the degree to which two variables change together. It indicates whether the variables increase or decrease simultaneously. A positive covariance indicates that as one variable increases, the other tends to increase as well. Conversely, a negative covariance indicates that as one variable increases, the other tends to decrease. However, covariance alone does not provide information about the strength or direction of the relationship.
Formula for Covariance (for a sample): Cov(X, Y) = Σ((Xi - X̄)(Yi - Ȳ)) / (n - 1)
Where:
         * Cov(X, Y) is the covariance between variables X and Y.
         * Xi and Yi are individual data points in the X and Y datasets, respectively.
         * X̄ and Ȳ are the sample means of the X and Y datasets, respectively.
         * n is the number of data points in the datasets.
Correlation:
Correlation, on the other hand, is a standardized measure that provides the strength and direction of the relationship between two variables. It normalizes the covariance by dividing it by the product of the standard deviations of the two variables, resulting in a value between -1 and +1. A correlation of +1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship.
Formula for Correlation (for a sample): Corr(X, Y) = Cov(X, Y) / (sX * sY)
Where:
         * Corr(X, Y) is the correlation coefficient between variables X and Y.
         * Cov(X, Y) is the covariance between variables X and Y.
         * sX and sY are the sample standard deviations of variables X and Y, respectively.
Both covariance and correlation are used to analyze the relationship between two variables in a dataset:
         1. Covariance: Covariance provides a measure of the direction of the relationship (positive or negative) between two variables. However, the value of covariance itself does not give information about the strength of the relationship or its significance, making it less interpretable than correlation.
         2. Correlation: Correlation provides a standardized measure of the strength and direction of the linear relationship between two variables. It is widely used because it is scale-independent, making it easier to interpret and compare across different datasets. Positive correlation values indicate that the variables move together, while negative correlation values indicate that they move in opposite directions. A correlation close to +1 or -1 indicates a strong linear relationship, while a correlation close to 0 suggests a weak or no linear relationship.
Q11. What is the formula for calculating the sample mean? Provide an example calculation for a dataset.
The formula for calculating the sample mean is:
Sample Mean (x̄) = (Sum of all data points) / (Number of data points)
In mathematical notation: x̄ = (Σ Xi) / n
Where:
         * x̄ is the sample mean.
         * Σ represents the summation symbol (sum of all data points).
         * Xi represents individual data points in the dataset.
         * n is the number of data points in the sample.
Example : Taking the grades of a sample student = [81,79,90,98,92]
Number of samples (n) = 5
Mean = (81+79+90+98+92)/5 = 440/5 = 88
Therefore the Mean of the sample data is 88
Q12. For a normal distribution data what is the relationship between its measure of central tendency?
For a normal distribution, the three measures of central tendency, namely the mean, median, and mode, are all equal to each other. In a perfectly symmetrical normal distribution, the data is evenly distributed around the center, resulting in the same value for each measure of central tendency.
Mean = Median = Mode
The relationship between the measures of central tendency in a normal distribution is as follows:
Mean: The mean of a normal distribution is located at the center of the distribution, and it is equal to the median and the mode.
Median: The median of a normal distribution is also located at the center of the distribution, and it is equal to the mean and the mode.
Mode: The mode of a normal distribution is the peak point of the curve, and it is equal to both the mean and the median.
This equality between the mean, median, and mode in a normal distribution is a characteristic of its symmetry. The symmetrical shape of the normal distribution curve is bell-shaped, and half of the data lies on either side of the mean, resulting in the median being the same as the mean and mode.
Q13. How is covariance different from correlation?
Covariance and Correlation are useful measures in statistical analysis to assess the relationship between two variables. Covariance gives the direction of the relationship, while correlation provides a standardized measure of both direction and strength.
Covariance:
Covariance measures the degree to which two variables change together. It indicates whether the variables increase or decrease simultaneously. A positive covariance indicates that as one variable increases, the other tends to increase as well. Conversely, a negative covariance indicates that as one variable increases, the other tends to decrease. However, covariance alone does not provide information about the strength or direction of the relationship.
Formula for Covariance (for a sample): Cov(X, Y) = Σ((Xi - X̄)(Yi - Ȳ)) / (n - 1)
Where:
         * Cov(X, Y) is the covariance between variables X and Y.
         * Xi and Yi are individual data points in the X and Y datasets, respectively.
         * X̄ and Ȳ are the sample means of the X and Y datasets, respectively.
         * n is the number of data points in the datasets.
Correlation:
Correlation, on the other hand, is a standardized measure that provides the strength and direction of the relationship between two variables. It normalizes the covariance by dividing it by the product of the standard deviations of the two variables, resulting in a value between -1 and +1. A correlation of +1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship.
Formula for Correlation (for a sample): Corr(X, Y) = Cov(X, Y) / (sX * sY)
Where:
         * Corr(X, Y) is the correlation coefficient between variables X and Y.
         * Cov(X, Y) is the covariance between variables X and Y.
         * sX and sY are the sample standard deviations of variables X and Y, respectively.
Covariance and Correlation are useful measures in statistical analysis to assess the relationship between two variables. Covariance gives the direction of the relationship, while correlation provides a standardized measure of both direction and strength.